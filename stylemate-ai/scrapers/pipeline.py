#!/usr/bin/env python3
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Disable all GPU/MPS backends before importing torch/faiss
# (This avoids MPS/CUDAâ€related segfaults on Mac, etc.)
import os
os.environ["CUDA_VISIBLE_DEVICES"] = ""
# Prevent MPS backend from initializing:
import torch
torch.backends.mps.is_available = lambda: False
torch.backends.mps.is_built     = lambda: False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import sys
import importlib
import argparse
import json
import numpy as np
import faiss
import requests
from io import BytesIO
from PIL import Image

# â”€â”€â”€ MAKE SURE PROJECT ROOT IS ON sys.path â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# so that `import clip_model` (and others in root) works from here.
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if root_dir not in sys.path:
    sys.path.insert(0, root_dir)

# â”€â”€â”€ IMPORT CLIP MODEL TO EMBED IMAGES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import clip_model  # your clip_model.py lives at project root; it defines `model` and `preprocess`

# â”€â”€ UTILITY: fetch an image from its URL â†’ PIL.Image â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_image(url: str) -> Image.Image:
    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    return Image.open(BytesIO(resp.content)).convert("RGB")

# â”€â”€ UTILITY: given a PIL image, return a normalized embed as a Python list â”€â”€
def embed_image(img: Image.Image) -> list:
    x = clip_model.preprocess(img).unsqueeze(0)  # 1Ã—3Ã—224Ã—224
    with torch.no_grad():
        emb = clip_model.model.encode_image(x)    # 1Ã—D
        emb = emb / emb.norm(dim=-1, keepdim=True)
    return emb.squeeze().tolist()

# â”€â”€ UTILITY: build & write a Faiss index (inner product on L2â€normalized vectors) â”€
def build_faiss_index_from_vectors(vectors_list: list, metas_list: list, index_path: str, metas_path: str):
    # Convert to numpy float32
    vectors_np = np.array(vectors_list, dtype="float32")
    # Normalize for cosine search
    faiss.normalize_L2(vectors_np)
    # Create a flat Innerâ€Product index
    dim = vectors_np.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(vectors_np)
    # Write the index to disk
    faiss.write_index(index, index_path)
    # Write metadata JSON
    with open(metas_path, "w", encoding="utf-8") as mf:
        json.dump(metas_list, mf, indent=2, ensure_ascii=False)
    print(f"âœ… Indexed {len(metas_list)} entries â†’ {index_path}")

# â”€â”€ MAIN PIPELINE FUNCTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_full_pipeline(scraper_module: str, output_folder: str):
    """
    1) Dynamically import `scrapers/{scraper_module}.py` and call `scrape()`.
    2) Write scraped products â†’ <brand>_products.json
    3) Embed each product image â†’ <brand>_product_vectors.json
    4) Build a Faiss index + write <brand>.index + <brand>_metas.json
    """
    # 1) Import the scraper module
    try:
        scraper = importlib.import_module(f"scrapers.{scraper_module}")
    except ImportError as e:
        print(f"âŒ Error: could not import scraper `scrapers/{scraper_module}.py`: {e}")
        sys.exit(1)

    if not hasattr(scraper, "scrape"):
        print(f"âŒ Error: `{scraper_module}.py` must define a function `scrape()`.")
        sys.exit(1)

    print(f"\nğŸ” Running scraper `scrapers/{scraper_module}.py` â€¦")
    products = scraper.scrape()
    brand_name = scraper_module.replace("_scraper", "")  # e.g. "galore_scraper" â†’ "galore"

    # 2) Write scraped products to JSON
    os.makedirs(output_folder, exist_ok=True)
    products_path = os.path.join(output_folder, f"{brand_name}_products.json")
    print(f"   â€¢ Writing scraped data ({len(products)} items) â†’ {products_path}")
    with open(products_path, "w", encoding="utf-8") as pf:
        json.dump(products, pf, indent=2, ensure_ascii=False)

    # 3) Embed images and collect (meta, vector)
    embeddings = []
    metas = []
    print(f"\nğŸ” Embedding {len(products)} images â€¦")
    # Ensure model is on CPU
    device = torch.device("cpu")
    clip_model.model.to(device).eval()

    for idx, prod in enumerate(products, start=1):
        title = prod.get("title", "<no-title>")
        image_url = prod.get("image_url", "")
        meta = { "title": title, "price": prod.get("price"), "url": prod.get("url") }

        if not image_url:
            print(f"âš ï¸  [{idx}] No image_url for {title!r}; skipping.")
            continue

        try:
            img = fetch_image(image_url)
            vec = embed_image(img)
            embeddings.append(vec)
            metas.append(meta)
            print(f"   âœ…  [{idx}] Embedded: {title!r}")
        except Exception as e:
            print(f"   âŒ  [{idx}] Failed to embed {title!r}: {e}")

    # 3b) Write out product_vectors.json
    vectors_path = os.path.join(output_folder, f"{brand_name}_product_vectors.json")
    print(f"\nğŸ’¾ Saving {len(embeddings)} vectors â†’ {vectors_path}")
    out_list = []
    for i in range(len(embeddings)):
        out_list.append({ "meta": metas[i], "vector": embeddings[i] })
    with open(vectors_path, "w", encoding="utf-8") as vf:
        json.dump(out_list, vf, indent=2, ensure_ascii=False)

    # 4) Build & save Faiss index + metas
    index_path = os.path.join(output_folder, f"{brand_name}.index")
    metas_path = os.path.join(output_folder, f"{brand_name}_metas.json")
    print(f"\nğŸ”¨ Building Faiss index for {brand_name} â€¦")
    build_faiss_index_from_vectors(embeddings, metas, index_path, metas_path)

    print("\nğŸ‰ Pipeline complete!\n")
    print(f"  â†³ Scraped JSON â†’     {products_path}")
    print(f"  â†³ Vector JSON â†’      {vectors_path}")
    print(f"  â†³ Faiss index â†’      {index_path}")
    print(f"  â†³ Metadata JSON â†’    {metas_path}\n")


# â”€â”€â”€ COMMANDâ€LINE INTERFACE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run full scrapeâ†’embedâ†’index pipeline for a given brand."
    )
    parser.add_argument(
        "--scraper", "-s", required=True,
        help="Name of the scraper under `scrapers/` (omit `.py`), e.g. `drmers_scraper` or `galore_scraper`."
    )
    parser.add_argument(
        "--outdir", "-o",
        default=os.path.abspath(os.path.join(root_dir, "data")),
        help="Output directory for JSON + index files (default: <project>/data)"
    )
    args = parser.parse_args()
    run_full_pipeline(args.scraper, args.outdir)
